diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 05c9aa33..1df6da00 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -2262,7 +2262,7 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 	/*
 	 * Make sure we do not leak PI boosting priority to the child.
 	 */
-	//p->prio = current->normal_prio;
+	p->prio = current->normal_prio;
 
 	/*
 	 * Revert to default priority/policy on fork if requested.
@@ -2307,14 +2307,6 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 	raw_spin_lock_irqsave(&p->pi_lock, flags);
 	set_task_cpu(p, cpu);
 	raw_spin_unlock_irqrestore(&p->pi_lock, flags);
-	
-	if (p->policy == SCHED_NORMAL) {
-		p->prio = current->normal_prio - NICE_WIDTH - PRIO_TO_NICE(current->static_prio);
-		p->normal_prio = p->prio;
-		p->rt_priority = p->prio;
-		p->policy = SCHED_FIFO;
-		p->static_prio = NICE_TO_PRIO(0);
-	}
 
 #ifdef CONFIG_SCHED_INFO
 	if (likely(sched_info_on()))
@@ -4238,11 +4230,6 @@ static int _sched_setscheduler(struct task_struct *p, int policy,
 		attr.sched_policy = policy;
 	}
 
-	if (attr.sched_policy == SCHED_NORMAL) {
-		attr.sched_priority = param->sched_priority - NICE_WIDTH - attr.sched_nice;
-		attr.sched_policy = SCHED_FIFO;
-	}
-
 	return __sched_setscheduler(p, &attr, check, true);
 }
 /**
diff --git a/kernel/sched/rt.c b/kernel/sched/rt.c
index 2d6ee020..541b8494 100644
--- a/kernel/sched/rt.c
+++ b/kernel/sched/rt.c
@@ -2319,7 +2319,6 @@ static void task_tick_rt(struct rq *rq, struct task_struct *p, int queued)
 	 * RR tasks need a special form of timeslice management.
 	 * FIFO tasks have no timeslices.
 	 */
-	p->rt.time_slice = sched_rr_timeslice;
 	if (p->policy != SCHED_RR)
 		return;
 
